{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6773542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f74093d",
   "metadata": {},
   "source": [
    "#### To avoid overfitting, we apply some transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ddd761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image augmentation of the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True)\n",
    "\n",
    "# train_set = train_datagen.flow_from_directory(\n",
    "#     'C:/Users/Hp/Documents/Coursera/Deep Learning/CNN/dataset/training_set', \n",
    "#     target_size=(64, 64), \n",
    "#     batch_size=32, \n",
    "#     class_mode='binary')\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    'dataset/training_set', \n",
    "    target_size=(64, 64), \n",
    "    batch_size=32, \n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07214894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test_set', \n",
    "    target_size=(64, 64), \n",
    "    batch_size=32, \n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226c640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[[0.3876175 , 0.61073333, 0.7587214 ],\n",
      "         [0.3876175 , 0.61073333, 0.7587214 ],\n",
      "         [0.3876175 , 0.61073333, 0.7587214 ],\n",
      "         ...,\n",
      "         [0.47450984, 0.53333336, 0.56078434],\n",
      "         [0.47450984, 0.53333336, 0.56078434],\n",
      "         [0.47450984, 0.53333336, 0.56078434]],\n",
      "\n",
      "        [[0.38926926, 0.61672026, 0.7618183 ],\n",
      "         [0.38926926, 0.61672026, 0.7618183 ],\n",
      "         [0.38926926, 0.61672026, 0.7618183 ],\n",
      "         ...,\n",
      "         [0.47628525, 0.53510875, 0.5625597 ],\n",
      "         [0.47628525, 0.53510875, 0.5625597 ],\n",
      "         [0.47628525, 0.53510875, 0.5625597 ]],\n",
      "\n",
      "        [[0.403223  , 0.630674  , 0.7757721 ],\n",
      "         [0.403223  , 0.630674  , 0.7757721 ],\n",
      "         [0.403223  , 0.630674  , 0.7757721 ],\n",
      "         ...,\n",
      "         [0.487026  , 0.54584956, 0.57330054],\n",
      "         [0.487026  , 0.54584956, 0.57330054],\n",
      "         [0.487026  , 0.54584956, 0.57330054]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.45098042, 0.687296  , 0.8527004 ],\n",
      "         [0.45098042, 0.687296  , 0.8527004 ],\n",
      "         [0.45098042, 0.687296  , 0.8527004 ],\n",
      "         ...,\n",
      "         [0.62325954, 0.6357228 , 0.64856184],\n",
      "         [0.62325954, 0.6357228 , 0.64856184],\n",
      "         [0.62325954, 0.6357228 , 0.64856184]],\n",
      "\n",
      "        [[0.43595737, 0.68087006, 0.8366206 ],\n",
      "         [0.43595737, 0.68087006, 0.8366206 ],\n",
      "         [0.43595737, 0.68087006, 0.8366206 ],\n",
      "         ...,\n",
      "         [0.64899075, 0.664677  , 0.6678571 ],\n",
      "         [0.64899075, 0.664677  , 0.6678571 ],\n",
      "         [0.64899075, 0.664677  , 0.6678571 ]],\n",
      "\n",
      "        [[0.41341403, 0.6536612 , 0.79442406],\n",
      "         [0.41341403, 0.6536612 , 0.79442406],\n",
      "         [0.41341403, 0.6536612 , 0.79442406],\n",
      "         ...,\n",
      "         [0.6949449 , 0.71207625, 0.70381945],\n",
      "         [0.6949449 , 0.71207625, 0.70381945],\n",
      "         [0.6949449 , 0.71207625, 0.70381945]]],\n",
      "\n",
      "\n",
      "       [[[0.24478988, 0.13051389, 0.04835007],\n",
      "         [0.30188933, 0.15359542, 0.05244494],\n",
      "         [0.32383752, 0.1747634 , 0.08808027],\n",
      "         ...,\n",
      "         [0.05533934, 0.00855227, 0.01630482],\n",
      "         [0.05494791, 0.00788909, 0.01573222],\n",
      "         [0.05847389, 0.01141507, 0.01925821]],\n",
      "\n",
      "        [[0.22684857, 0.10461318, 0.02069716],\n",
      "         [0.2768684 , 0.14302637, 0.05557728],\n",
      "         [0.28483918, 0.14688636, 0.06415242],\n",
      "         ...,\n",
      "         [0.06207215, 0.00811809, 0.01767359],\n",
      "         [0.06210737, 0.00786103, 0.01750105],\n",
      "         [0.06566747, 0.01142113, 0.02106115]],\n",
      "\n",
      "        [[0.22622035, 0.09394936, 0.0103275 ],\n",
      "         [0.23450322, 0.11605262, 0.04966573],\n",
      "         [0.23368578, 0.11214602, 0.03438963],\n",
      "         ...,\n",
      "         [0.06643132, 0.00400002, 0.01568628],\n",
      "         [0.07038026, 0.00763516, 0.01939987],\n",
      "         [0.0741723 , 0.0114272 , 0.02319191]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.02490586, 0.01132513, 0.01254665],\n",
      "         [0.16535212, 0.09001039, 0.06110356],\n",
      "         [0.18131629, 0.0911202 , 0.03621823],\n",
      "         ...,\n",
      "         [0.58139116, 0.4148662 , 0.55263585],\n",
      "         [0.4049665 , 0.24718243, 0.2856983 ],\n",
      "         [0.4439861 , 0.3001117 , 0.3265896 ]],\n",
      "\n",
      "        [[0.02012168, 0.01270283, 0.00962644],\n",
      "         [0.17357688, 0.08202513, 0.04929033],\n",
      "         [0.1743001 , 0.08197934, 0.03132676],\n",
      "         ...,\n",
      "         [0.49568453, 0.3503864 , 0.47590634],\n",
      "         [0.45254233, 0.31133518, 0.38127273],\n",
      "         [0.48184532, 0.35151973, 0.42509928]],\n",
      "\n",
      "        [[0.01643299, 0.01413662, 0.00741795],\n",
      "         [0.1836534 , 0.07843138, 0.04247693],\n",
      "         [0.17238678, 0.07826912, 0.03121029],\n",
      "         ...,\n",
      "         [0.43509227, 0.33475792, 0.43764937],\n",
      "         [0.44327417, 0.33789253, 0.42273903],\n",
      "         [0.5038321 , 0.39663738, 0.5029322 ]]],\n",
      "\n",
      "\n",
      "       [[[0.32857656, 0.21485107, 0.22483377],\n",
      "         [0.34062013, 0.22823814, 0.23945823],\n",
      "         [0.3631555 , 0.2629767 , 0.28543636],\n",
      "         ...,\n",
      "         [0.48511556, 0.42443052, 0.45281225],\n",
      "         [0.5106027 , 0.43824232, 0.47110808],\n",
      "         [0.53476036, 0.45632896, 0.49162307]],\n",
      "\n",
      "        [[0.3694682 , 0.2557427 , 0.2724648 ],\n",
      "         [0.3346521 , 0.2213059 , 0.23832384],\n",
      "         [0.34435493, 0.23439191, 0.25396845],\n",
      "         ...,\n",
      "         [0.48338702, 0.4227282 , 0.45109683],\n",
      "         [0.49717095, 0.42474505, 0.45763698],\n",
      "         [0.48834786, 0.40991646, 0.4452106 ]],\n",
      "\n",
      "        [[0.48407075, 0.36934337, 0.3919568 ],\n",
      "         [0.4212323 , 0.3056747 , 0.3277579 ],\n",
      "         [0.34645405, 0.22414695, 0.24161936],\n",
      "         ...,\n",
      "         [0.51280373, 0.45217106, 0.48052663],\n",
      "         [0.52000564, 0.4475142 , 0.48043236],\n",
      "         [0.50609124, 0.4276598 , 0.46295393]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.49498132, 0.38223454, 0.3797844 ],\n",
      "         [0.4904366 , 0.36950305, 0.37337056],\n",
      "         [0.5013459 , 0.37127203, 0.38222948],\n",
      "         ...,\n",
      "         [0.5576372 , 0.4475699 , 0.4331825 ],\n",
      "         [0.50410336, 0.38728654, 0.39274505],\n",
      "         [0.48436376, 0.36027068, 0.37133685]],\n",
      "\n",
      "        [[0.4615572 , 0.3585339 , 0.3665474 ],\n",
      "         [0.4858732 , 0.3764831 , 0.3869759 ],\n",
      "         [0.48717177, 0.3678282 , 0.3813186 ],\n",
      "         ...,\n",
      "         [0.58944935, 0.45938256, 0.4668449 ],\n",
      "         [0.54813784, 0.4240442 , 0.4344318 ],\n",
      "         [0.4897868 , 0.36465868, 0.37624237]],\n",
      "\n",
      "        [[0.4478381 , 0.34721217, 0.36862132],\n",
      "         [0.4551078 , 0.35018453, 0.37015572],\n",
      "         [0.45952317, 0.3508839 , 0.36278763],\n",
      "         ...,\n",
      "         [0.6159984 , 0.49300238, 0.50298506],\n",
      "         [0.6116481 , 0.48640522, 0.4979932 ],\n",
      "         [0.5200711 , 0.39458087, 0.40634558]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.1137255 , 0.1764706 , 0.        ],\n",
      "         [0.2716734 , 0.38248962, 0.2437892 ],\n",
      "         [0.41152194, 0.46010765, 0.27152526],\n",
      "         ...,\n",
      "         [0.86023724, 0.9266223 , 0.9153667 ],\n",
      "         [0.607404  , 0.636248  , 0.4965708 ],\n",
      "         [0.62352943, 0.65882355, 0.43529415]],\n",
      "\n",
      "        [[0.1137255 , 0.1764706 , 0.        ],\n",
      "         [0.27152112, 0.382291  , 0.24355415],\n",
      "         [0.41140938, 0.4600613 , 0.27153188],\n",
      "         ...,\n",
      "         [0.86049885, 0.9269236 , 0.9157805 ],\n",
      "         [0.6073874 , 0.6362248 , 0.49663368],\n",
      "         [0.62352943, 0.65882355, 0.43529415]],\n",
      "\n",
      "        [[0.1137255 , 0.1764706 , 0.        ],\n",
      "         [0.27136883, 0.38209236, 0.24331911],\n",
      "         [0.4112968 , 0.46001497, 0.2715385 ],\n",
      "         ...,\n",
      "         [0.8607604 , 0.9272248 , 0.9161944 ],\n",
      "         [0.6073709 , 0.6362016 , 0.49669656],\n",
      "         [0.62352943, 0.65882355, 0.43529415]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.454902  , 0.47058827, 0.33333334],\n",
      "         [0.4613654 , 0.47058827, 0.4011992 ],\n",
      "         [0.28393334, 0.26251638, 0.2206189 ],\n",
      "         ...,\n",
      "         [0.42103326, 0.42495483, 0.4039216 ],\n",
      "         [0.44126335, 0.44518492, 0.41381237],\n",
      "         [0.50980395, 0.5137255 , 0.48235297]],\n",
      "\n",
      "        [[0.454902  , 0.47058827, 0.33333334],\n",
      "         [0.4613588 , 0.47058827, 0.4011297 ],\n",
      "         [0.28411543, 0.26272824, 0.22081754],\n",
      "         ...,\n",
      "         [0.4210233 , 0.42494488, 0.4039216 ],\n",
      "         [0.44119713, 0.4451187 , 0.41374615],\n",
      "         [0.50980395, 0.5137255 , 0.48235297]],\n",
      "\n",
      "        [[0.454902  , 0.47058827, 0.33333334],\n",
      "         [0.46135214, 0.47058827, 0.40106016],\n",
      "         [0.2842975 , 0.26294014, 0.22101617],\n",
      "         ...,\n",
      "         [0.42101339, 0.42493495, 0.4039216 ],\n",
      "         [0.44113094, 0.4450525 , 0.41367996],\n",
      "         [0.50980395, 0.5137255 , 0.48235297]]],\n",
      "\n",
      "\n",
      "       [[[0.78823537, 0.8588236 , 0.91372555],\n",
      "         [0.78823537, 0.8588236 , 0.91372555],\n",
      "         [0.78823537, 0.8588236 , 0.91372555],\n",
      "         ...,\n",
      "         [0.506105  , 0.48649713, 0.47473243],\n",
      "         [0.506105  , 0.48649713, 0.47473243],\n",
      "         [0.506105  , 0.48649713, 0.47473243]],\n",
      "\n",
      "        [[0.79680336, 0.8673916 , 0.9165816 ],\n",
      "         [0.79680336, 0.8673916 , 0.9165816 ],\n",
      "         [0.79680336, 0.8673916 , 0.9165816 ],\n",
      "         ...,\n",
      "         [0.47945347, 0.47126964, 0.45664892],\n",
      "         [0.47945347, 0.47126964, 0.45664892],\n",
      "         [0.47945347, 0.47126964, 0.45664892]],\n",
      "\n",
      "        [[0.8000001 , 0.8705883 , 0.9176471 ],\n",
      "         [0.8000001 , 0.8705883 , 0.9176471 ],\n",
      "         [0.8000001 , 0.8705883 , 0.9176471 ],\n",
      "         ...,\n",
      "         [0.48805642, 0.47700495, 0.4636953 ],\n",
      "         [0.48805642, 0.47700495, 0.4636953 ],\n",
      "         [0.48805642, 0.47700495, 0.4636953 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.39382032, 0.36803275, 0.3429584 ],\n",
      "         [0.39382032, 0.36803275, 0.3429584 ],\n",
      "         [0.39382032, 0.36803275, 0.3429584 ],\n",
      "         ...,\n",
      "         [0.5224004 , 0.49815774, 0.48793796],\n",
      "         [0.5224004 , 0.49815774, 0.48793796],\n",
      "         [0.5224004 , 0.49815774, 0.48793796]],\n",
      "\n",
      "        [[0.3853793 , 0.355413  , 0.3258309 ],\n",
      "         [0.3853793 , 0.355413  , 0.3258309 ],\n",
      "         [0.3853793 , 0.355413  , 0.3258309 ],\n",
      "         ...,\n",
      "         [0.5176471 , 0.48627454, 0.4784314 ],\n",
      "         [0.5176471 , 0.48627454, 0.4784314 ],\n",
      "         [0.5176471 , 0.48627454, 0.4784314 ]],\n",
      "\n",
      "        [[0.38295954, 0.36727327, 0.33197916],\n",
      "         [0.38295954, 0.36727327, 0.33197916],\n",
      "         [0.38295954, 0.36727327, 0.33197916],\n",
      "         ...,\n",
      "         [0.51178515, 0.48217118, 0.47374183],\n",
      "         [0.51178515, 0.48217118, 0.47374183],\n",
      "         [0.51178515, 0.48217118, 0.47374183]]],\n",
      "\n",
      "\n",
      "       [[[0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         ...,\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ]],\n",
      "\n",
      "        [[0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         ...,\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ]],\n",
      "\n",
      "        [[0.98823535, 0.98574233, 0.9985715 ],\n",
      "         [0.98823535, 0.98574233, 0.9985715 ],\n",
      "         [0.98823535, 0.98574233, 0.9985715 ],\n",
      "         ...,\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ],\n",
      "         [0.98823535, 0.9843138 , 1.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7062772 , 0.62496096, 0.47521317],\n",
      "         [0.7062772 , 0.62496096, 0.47521317],\n",
      "         [0.7062772 , 0.62496096, 0.47521317],\n",
      "         ...,\n",
      "         [0.2845097 , 0.28490153, 0.3009241 ],\n",
      "         [0.2845097 , 0.28490153, 0.3009241 ],\n",
      "         [0.2845097 , 0.28490153, 0.3009241 ]],\n",
      "\n",
      "        [[0.6104791 , 0.46009806, 0.38851482],\n",
      "         [0.6104791 , 0.46009806, 0.38851482],\n",
      "         [0.6104791 , 0.46009806, 0.38851482],\n",
      "         ...,\n",
      "         [0.43947157, 0.347693  , 0.33390352],\n",
      "         [0.43947157, 0.347693  , 0.33390352],\n",
      "         [0.43947157, 0.347693  , 0.33390352]],\n",
      "\n",
      "        [[0.4666667 , 0.27058825, 0.23529413],\n",
      "         [0.4666667 , 0.27058825, 0.23529413],\n",
      "         [0.4666667 , 0.27058825, 0.23529413],\n",
      "         ...,\n",
      "         [0.5254902 , 0.39607847, 0.36078432],\n",
      "         [0.5254902 , 0.39607847, 0.36078432],\n",
      "         [0.5254902 , 0.39607847, 0.36078432]]]], dtype=float32), array([1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
      "       0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
      "      dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "#from the output returned by the line below, we can see that the code above tranformed the \n",
    "#images into image data, and also normalized the image\n",
    "print(train_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780b227",
   "metadata": {},
   "source": [
    "### Build the ConNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2bbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c191bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "# #Flattening the result of the convolution into a single vector\n",
    "# cnn.add(tf.keras.layers.Flatten())\n",
    "# #Add a fully connected layer\n",
    "# cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "# #Add an output layer\n",
    "# cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c99b5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421a648",
   "metadata": {},
   "source": [
    "### Training the ConvNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92a1d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start with the compilaton\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c95d5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 124s 495ms/step - loss: 0.6700 - accuracy: 0.6181 - val_loss: 0.6642 - val_accuracy: 0.6170\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 35s 139ms/step - loss: 0.5793 - accuracy: 0.6998 - val_loss: 0.5827 - val_accuracy: 0.6980\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.5570 - accuracy: 0.7205 - val_loss: 0.5694 - val_accuracy: 0.7115\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.5390 - accuracy: 0.7283 - val_loss: 0.5226 - val_accuracy: 0.7435\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.5240 - accuracy: 0.7324 - val_loss: 0.5174 - val_accuracy: 0.7520\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.5123 - accuracy: 0.7483 - val_loss: 0.5511 - val_accuracy: 0.7300\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.4920 - accuracy: 0.7585 - val_loss: 0.5178 - val_accuracy: 0.7615\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.4801 - accuracy: 0.7616 - val_loss: 0.5092 - val_accuracy: 0.7680\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.4642 - accuracy: 0.7750 - val_loss: 0.5356 - val_accuracy: 0.7555\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.4598 - accuracy: 0.7801 - val_loss: 0.4951 - val_accuracy: 0.7745\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.4575 - accuracy: 0.7843 - val_loss: 0.5562 - val_accuracy: 0.7540\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.4371 - accuracy: 0.7952 - val_loss: 0.6237 - val_accuracy: 0.6985\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.4390 - accuracy: 0.7950 - val_loss: 0.4986 - val_accuracy: 0.7775\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.4177 - accuracy: 0.8058 - val_loss: 0.5185 - val_accuracy: 0.7740\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.4178 - accuracy: 0.8064 - val_loss: 0.5563 - val_accuracy: 0.7670\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.4035 - accuracy: 0.8124 - val_loss: 0.5245 - val_accuracy: 0.7700\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 33s 130ms/step - loss: 0.3955 - accuracy: 0.8224 - val_loss: 0.5327 - val_accuracy: 0.7715\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 34s 135ms/step - loss: 0.3824 - accuracy: 0.8265 - val_loss: 0.5371 - val_accuracy: 0.7695\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 33s 133ms/step - loss: 0.3727 - accuracy: 0.8317 - val_loss: 0.5519 - val_accuracy: 0.7725\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.3669 - accuracy: 0.8326 - val_loss: 0.5726 - val_accuracy: 0.7525\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.3546 - accuracy: 0.8421 - val_loss: 0.5569 - val_accuracy: 0.7665\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.3534 - accuracy: 0.8430 - val_loss: 0.6013 - val_accuracy: 0.7655\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 33s 132ms/step - loss: 0.3380 - accuracy: 0.8503 - val_loss: 0.5830 - val_accuracy: 0.7510\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 32s 130ms/step - loss: 0.3383 - accuracy: 0.8516 - val_loss: 0.5750 - val_accuracy: 0.7650\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 33s 131ms/step - loss: 0.3176 - accuracy: 0.8616 - val_loss: 0.8431 - val_accuracy: 0.7085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e9ca1d9bd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "cnn.fit(x=train_set, validation_data = test_set, epochs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5ce2b5",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88646a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "#load the image from directory\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "#convert the image to array\n",
    "test_image = image.img_to_array(test_image)\n",
    "#group the image data into batch\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "#result = cnn.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79d92b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n"
     ]
    }
   ],
   "source": [
    "result = cnn.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "267ce86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.class_indices\n",
    "if result[0][0] > 0.5:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3cd0ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc1af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
